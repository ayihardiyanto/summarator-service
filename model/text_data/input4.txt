Today there is a huge amount of information from a lot of various resources such as World Wide Web, news articles, e-books and emails. On the one hand, human beings face a shortage of time, and on the other hand, due to the social and occupational needs, they need to obtain the most important information from various resources. Automatic
text
summarization enables us to access the most important content in the shortest possible time. In this paper a query-oriented text summarization technique is proposed by extracting the most informative sentences. To this end, a number of features are extracted from the sentences, each of which evaluates the importance of the sentences from an aspect. In this paper 11 of the best features are extracted from each of the sentences. This paper has shown that use of more suitable features leads to improved summaries generated. In order to evaluate the automatic generated summaries, the ROUGE criterion has been used.
The huge growth of information in various sources,
including the World Wide Web, news articles, e-books and emails, has left mankind with a huge amount of information. The busy lifestyle of humans in the modern world has also minimized the time available for discovering information from this massive volume. This has led to the emergence of a kind of contradiction in the modern society of today's world. On the one hand, the lack of time and, on the other hand, the need to be aware of various information due to job and social needs, leads to requiring methods to facilitate access to information in the shortest possible time.
Because of this issue, the fields such as text mining, natural
language processing and artificial intelligence also have come together and seek to find a solution to this problem. The result of the researchers’ efforts in these fields has led to the emergence of an interesting and important topic calledautomatic text summarization. Automatic summarization of text documents in the shortest possible time has made it possible for people to access the most important content. Manual text summarization requires a large number of specialized people in different fields and spent a great deal of time and effort in this direction. It's not possible to produce summaries for texts without people specialized in different fields. These people, having enough knowledge and experience in the context of those texts, are able to do text summarization using the power of thought and reasoning. This suggests that automating this operation by the machine is a very useful process and requires the use of various information from areas such as artificial intelligence, natural language processing, and text mining.
Automatic text summarization faces some challenges. For
example, extracting the proper features for sentences and words in the text has a significant impact on the performance of the summarization system, leading to select the most appropriate sentences that contain the most important information about the main subject of the text. Text summarization methods are divided into two categories: extractive and abstractive. Extractive summarization extracts important sentences from source documents and group them together to generate summary. Abstractive summarization creates a brief useful summary by generating new sentences. In this paper we propose an extractive technique for query-oriented summarization.
The extractive summarization should identify and extract
the important sentences in a document. So far, various methods have been used in the extractive summarization method. One of these methods is TF-IDF [1]. This is a numerical criterion that indicates the importance of a word in a document among a corpus of documents. TF shows the frequency of a word in a document. IDF is a measure that reduces the weight of frequently occurring words in the corpus and increases the weight of words that rarely occur. The words with high TF-IDF value, have a strong relationship with the document in which they are located. Many people have used TF-IDF to measureexample [2], [3], [4], and [5].
Another method used in extractive summarization is fuzzy
logic in which, scoring sentences can be done using fuzzy logic. At first, appropriate features are extracted from the text. Then, with regard to the extracted features for each sentence, a score is calculated using the fuzzy system. There are also some works done in this area, including [6], [7], [8], [9], and [10].
Extractive summarization is also done using graph-based
methods. In this method, each sentence from the document is considered as a vertex in the graph. If there is a common semantic relationship between the two sentences, they will be connected and weighted through the edges. A graph-based ranking algorithm is used to decide the importance of a vertex in a graph. The most important vertices in this graph are considered as important sentences and included in the summary. Among those who have worked in this field can be mentioned [11], [12], [13], and [14].
Another method used in extractive summarization is LSA1.
The LSA method is an algebraic statistical method that derives the meaning and similarity of sentences based on words’ information [15]. The idea of using the LSA method for summarizing text documents was introduced in 2001 [16]. The LSA method is an automated technique for extracting relationships Between words in text documents. In this method, a Term-by-Sentence matrix is first created from the original text. Then SVD is applied to it. This action leads to the discovery of hidden dimensions that are related to the various topics discussed in the document. Finally, the resulting matrices are used to identify and extract the most important sentences. These were some of the work done in the field of extractive summarization.
The rest of the paper is as follows: part II describes the
proposed extractive summarization method. Part III expresses the experimental results. Finally, part IV concludes the paper.In this paper a query-oriented text Summarization technique using sentence extraction is proposed. In the extractive summarization technique, the most informative sentences in the text are identified and selected to attend in the summary. To identify sentences containing valuable information, a set of appropriate features are extracted from the text. Whatever the extracted features of the sentences are more appropriate, the most informative sentences are more accurately identified and the quality of the generated summary improves. Each of these features takes the importance of sentences
from a different perspective. In this paper, the proposed method by Ahuja has been improved by appending some appropriate query based features. The extracted features by Ahuja can be used for generic summarization but they are not sufficient for query based summarization. They are similarity between sentence to its document, the position of the sentence in the document, the length of the sentence, the existence of numerical data and the presence of proper nouns in the sentence. In order to identify both the informative and query relevant sentences, the feature set is enriched with a number of other appropriate features. The first set of features can identify informative sentences and the second set of appropriate features will help to extract the query relevant sentences. These features are related to the topic and headlines. Furthermore, skip bigrams are also considered in addition to the unigrams. Finally, by using more complete set of convenient features, better results in summarization is achieved. The results of the experiments show this improvement.