Sentence representation at the semantic level is a challenging task for natural language processing and Artificial Intelligence.
Despite the advances in word embeddings (i.e. word vector representations), capturing sentence meaning is an open question due to complexities of semantic interactions among words. In this paper, we present an embedding method, which is aimed at learning unsupervised sentence representations from unlabeled text. We propose an unsupervised method that models a sentence as a weighted series of word embeddings. The weights of the series are fitted by using Shannon’s Mutual Information (MI) among words, sentences and the corpus. In fact, the Term Frequency?Inverse Document Frequency transform (TF?IDF) is a reliable estimate of such MI. Our method offers advantages over existing ones: identifiable modules, short-term training, online inference of (unseen) sentence representations, as well as independence from domain, external knowledge and linguistic annotation resour- ces. Results showed that our model, despite its concreteness and low computational cost, was competitive with the state of the art in well-known Semantic Textual Similarity (STS) tasks. Ó 2019 Elsevier Ltd. All rights reserved.

Nowadays, the growth of information in digital media encourages the analysis of large amounts of text data. This
is attracting attention from Data Science and Artificial Intelligence researchers, as well as from the Internet industry. Internet users are responsible for a meaningful part of this growth. They enter information into the network which is also leveraged for sharing knowledge. An important part of this knowledge is found at repositories such as question & answer forums, digital newspapers and digital encyclopedias. Due to the innumerable duplication of the information at these repositories, several concerns arise as to the way
users feed and consume knowledge. Some of these concerns include removing redundancies in question-answering forums or exploiting redundancies to assess the confidence of news in media or simply to compress text size. The accomplishment of this massive information processing is clearly infeasible for human reviewers. In this scenario, Statistical Natural Language Processing (NLP) methods are a substantial aid. An approach to address these issues is to perform massive comparisons by considering the semantic content of
sentences or short snippets of text. These comparisons can be done by measuring Semantic Textual Similarity (STS) (Hatzivassiloglou et al., 1999; Agirre et al., 2012). STS consists in computing a similarity score (a real value) between a pair of sentences. This score indicates how similar the contents of the sentences of the pair are. There are, on the one hand, STS systems which employ a number of supervisory signals such as knowledge bases,
encyclopedias, linguistic annotation resources (e.g. thesaurus and linguistic taggers built on the basis of a Part-of- Speech [PoS] tagger) and even similarity labels (Mihalcea et al., 2006). Nevertheless, for specialized texts (or for low-resourced languages) those resources are not available or are scarce. Furthermore, the scope of such systems is limited exclusively to the task of measuring textual similarity. Such a limitation generally obviates the step of repre- senting sentence meaning. This is not desirable when we want to study statistical behavior of meaning. On the other hand, sentences (or short text snippets) can be embedded onto vector spaces such that approxima-
tions to their meanings can be represented geometrically as vectors, i.e. sentence embeddings or sentence representa- tions (Hinton et al., 1986; Elman, 1991). In this paper we study sentence representations because they allow for studying the statistical behavior of sentence meaning. As an additional and important benefit, sentence representa- tions make it possible to leverage a number of NLP tasks, such as sentence clustering, text summarization (Zhang et al., 2012; Arroyo-Fern?andez, 2015; Arroyo-Fernndez et al., 2016; Yu et al., 2017), sentence classification (Kalch- brenner et al., 2014; Chen et al., 2017; Er et al., 2016), paraphrase identification (Yin and Sch€utze, 2015), semantic similarity/relatedness (Yazdani and Popescu-Belis, 2013; De Boom et al., 2016; Arroyo-Fern?andez and Meza Ruiz, 2017) and sentiment classification (Kalchbrenner et al., 2014; Chen et al., 2017; Onan et al., 2017). The difficulty of representing text by embedding it into vector spaces mainly depends on its length. On the one
hand, most embedding methods provide well-suited representations of the content of texts which individual size is on a relatively large scale (Salton et al., 1983; Salton and Buckley, 1988; Martin and Berry, 2007; Le and Mikolov, 2014). For instance, book-sized texts (e.g. documents with hundreds of thousands of words or larger) are well repre- sented by the importance of the words they contain (Sp€ark Jones, 1972). Accordingly, by representing large text objects (e.g. as a Bag-of-Words, BoW) we can satisfy shallow (or low-complexity) information necessities limited to the gist (topics) of the documents (Manning et al., 2009; Kintsch and Mangalath, 2011), e.g. Information Retrieval and document classification. On the other hand, words are at the bottom end of the text size scale. At the word level, information necessities
can be very general. That is, word representation methods could be components of practically any NLP system. These methods are mainly based on a general principle called distributional hypothesis, which states that similar words are used in similar contexts (Firth, 1957; Harris, 1968). In the NLP area, this linguistic principle is usually implemented as statistical estimates of word co-occurrence, i.e. word embedding methods. These statistical estimates provide word embeddings performing well enough in general purpose NLP applications (Baroni and Lenci, 2010; Mikolov et al., 2013a; Pennington et al., 2014; Baroni et al., 2014; Bojanowski et al., 2016). The problem of modeling sentence meaning is still open. For the cases of documents or words, most applications
expect representations encoding text content or word use. Nonetheless, in the case of sentences, application users can expect composite representations providing much more specific or complex information, e.g. what is declared or denied about something (Pereira, 2000; Meza-Ruiz and Riedel, 2009; Collobert et al., 2011; Kintsch and Mangalath, 2011). Thus, state-of-the-art sentence representation methods can be highly dependent on the application and on its specificity. So it is difficult to keep their performance and behavior uniform/stable in several scenarios (Pham et al.,2015; Pagliardini et al., 2017). Advancing the state of the art on sentence representation can be specially useful when only unlabelled text is available for learning sentence representations or even for applications to low-resourced lan- guages. In this work we address the problem of sentence representation by means of the following hypothesis. It is possi-
ble to represent sentences well by exploiting the link between the contexts learned by word embeddings and the entropy of such embedded words given the text containing them. In order to confirm our hypothesis, we model a sen- tence as a weighted series of pretrained word embeddings. In this framework, the weight of each word embedding is learned in an unsupervised fashion by measuring the Shannon’s Mutual Information among its associated word, the sentence and the corpus containing it (Shannon, 1949). In this way, the weights regulate the amount of information provided by each word embedding to its corresponding sentence representation. We called this approach Word Infor- mation Series for Sentence Embedding (WISSE5). A good estimate of the mentioned measure is given by the well- known TF?IDF transform (Term Frequency?Inverse Document Frequency), and there are efficient implementa- tions of it. Notice that the role the weights play in our sentence representation model is the same than that played by the attention vector of a neural language model (Er et al., 2016; Yin et al., 2016). We evaluated our model in well-known STS tasks provided by multiple Semantic Evaluation workshops
(SemEval), i.e. SICK (2014), SemEval (2016) and STS Benchmark (2017). Our results showed that WISSE per- formed comparably with (or outperformed) strong state-of-the-art methods in such tasks. Additional advantages were observed, which were mainly due to the modularity and low computational cost of our model: short-term train- ing, independence from domain, external knowledge and linguistic annotation resources, as well as online inference of (unseen) sentence representations. The rest of this paper is organized as follows: Section 2 presents the related work. Section 3 presents the main dif-
ferences between STS systems and sentence representation methods. Section 4 exposes the motivations for our method. Section 5 presents the modules composing our model. In Section 6 we explain the constitution of our model and how the modules composing it interact. In Section 7 we explain the design of our experiments and their objec- tives. Section 8 presents the obtained results and Section 9 addresses the discussion about such results. Section 10 provides insights on possible improvements, including advantages and disadvantages. Finally, in Section 11 the con- clusions derived from this work are presented.

Our method outperformed the usual baselines of sentence representation on well-known STS tasks (BoW and
word embedding average). Furthermore, the evaluation on the SICK dataset showed that our method outperformed the state of the art methods by reaching a correlation of r ¼ 0:724. This is encouraging because measuring semantic similarity on this dataset is a difficult task for unsupervised sentence representation methods. In fact, the barrier of 0.72 is difficult to overcome for them. WISSE also reached state-of-the-art performance on the well-known SemEval (2016) STS task. Our experiments confirmed our hypothesis stating that it is possible to well represent sentences by using the link
between the contexts learned by word embeddings and the amount of information of words within a sentence. We exploited the mentioned link to learn without supervision the weights of a series of word embeddings representing a sentence. Interestingly, such weights are simple scalars that allowed our model to reach state-of-the-art performance in difficult STS tasks at low computational cost.